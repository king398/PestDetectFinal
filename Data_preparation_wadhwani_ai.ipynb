{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/king398/PestDetectFinal/blob/master/Data_preparation_wadhwani_ai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f_XnhAiVn-iT"
      },
      "outputs": [],
      "source": [
        "# Import libraries\n",
        "## Reference https://zindi.africa/learn/how-to-download-data-files-from-zindi-to-colab\n",
        "import requests\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Data url and token\n",
        "data_url_test = \"https://api.zindi.africa/v1/competitions/wadhwani-ai-bollworm-counting-challenge/files/Test.csv\"\n",
        "data_url_train = \"https://api.zindi.africa/v1/competitions/wadhwani-ai-bollworm-counting-challenge/files/Train.csv\"\n",
        "data_url_image_bboxes = 'https://api.zindi.africa/v1/competitions/wadhwani-ai-bollworm-counting-challenge/files/images_bboxes.csv'\n",
        "data_url_image_zip = 'https://api.zindi.africa/v1/competitions/wadhwani-ai-bollworm-counting-challenge/files/images.zip'\n",
        "data_url_Sample_Submission = 'https://api.zindi.africa/v1/competitions/wadhwani-ai-bollworm-counting-challenge/files/SampleSubmission.csv'\n",
        "\n",
        "token = {'auth_token': ''}  # Use your own token\n",
        "\n",
        "\n",
        "def zindi_data_downloader(url, token, file_name):\n",
        "    # Get the competition data\n",
        "    competition_data = requests.post(url=url, data=token, stream=True)\n",
        "\n",
        "    # Progress bar monitor download\n",
        "    pbar = tqdm(desc=file_name, total=int(competition_data.headers.get('content-length', 0)), unit='B', unit_scale=True,\n",
        "                unit_divisor=512)\n",
        "    # Create and Write the data to colab drive in chunks\n",
        "    handle = open(file_name, \"wb\")\n",
        "    for chunk in competition_data.iter_content(chunk_size=512):  # Download the data in chunks\n",
        "        if chunk:  # filter out keep-alive new chunks\n",
        "            handle.write(chunk)\n",
        "        pbar.update(len(chunk))\n",
        "    handle.close()\n",
        "    pbar.close()\n",
        "\n",
        "\n",
        "zindi_data_downloader(url=data_url_test, token=token, file_name='Test.csv')\n",
        "zindi_data_downloader(url=data_url_train, token=token, file_name='Train.csv')\n",
        "zindi_data_downloader(url=data_url_image_bboxes,token=token,file_name='images_bboxes.csv')\n",
        "zindi_data_downloader(url=data_url_image_zip,token=token,file_name='images.zip')\n",
        "zindi_data_downloader(url=data_url_Sample_Submission,token=token,file_name='SampleSubmission.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9yITCzCTs0tR"
      },
      "outputs": [],
      "source": [
        "!mkdir images\n",
        "!unzip -qq /content/images.zip -d images \n",
        "!rm  /content/images.zip\n",
        "!pip install pybboxes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import cv2\n",
        "from tqdm.auto import tqdm\n",
        "from joblib import Parallel, delayed\n",
        "import os\n",
        "from shapely.wkt import loads\n",
        "from pybboxes import BoundingBox\n",
        "import shutil\n",
        "\n",
        "train = pd.read_csv('/content/Train.csv')\n",
        "test = pd.read_csv('/content/Test.csv')\n",
        "train_bbox = pd.read_csv('/content/images_bboxes.csv')\n",
        "train_bbox = train_bbox.dropna(axis=0)\n",
        "print(train_bbox.head())\n",
        "image_sizes = {}\n",
        "os.makedirs('train_images', exist_ok=True)\n",
        "os.makedirs('test_images', exist_ok=True)\n",
        "\n",
        "os.makedirs('labels', exist_ok=True)\n",
        "\n",
        "\n",
        "def resize_and_append(i):\n",
        "    id = train.loc[i, 'image_id_worm']\n",
        "    img = cv2.imread(f'/content/images/{id}')\n",
        "    shape = img.shape\n",
        "    img = cv2.resize(img, (1024, 1024))\n",
        "    cv2.imwrite(f'/content/images/{id}', img)\n",
        "    return id, shape\n",
        "\n",
        "\n",
        "shapes = Parallel(n_jobs=4)(delayed(resize_and_append)(i) for i in tqdm(train.index))\n",
        "for i in shapes:\n",
        "    image_sizes.update({i[0]: i[1]})\n",
        "shapes = image_sizes\n",
        "for i in train['image_id_worm']:\n",
        "    shutil.copy(f'/content/images/{i}', f'/content/train_images/{i}')\n",
        "for i in test['image_id_worm']:\n",
        "    shutil.copy(f'/content/images/{i}', f'/content/test_images/{i}')\n"
      ],
      "metadata": {
        "id": "kurmmyht6XEt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_bbox['worm_type'] = train_bbox['worm_type'].apply(lambda x: 0 if x == 'pbw' else 1)\n",
        "train_bbox = train_bbox.dropna(axis=0)\n",
        "\n",
        "ids_to_remove = []\n",
        "\n",
        "\n",
        "def make_labels(id):\n",
        "    bboxes_temp = train_bbox[train_bbox['image_id'] == id]\n",
        "    try:\n",
        "        shape = shapes[id]\n",
        "        label = \"\"\n",
        "        for i in bboxes_temp.index:\n",
        "            try:\n",
        "                bbox = bboxes_temp.loc[i, 'geometry']\n",
        "                bbox = loads(str(bbox))\n",
        "\n",
        "                bbox = bbox.bounds\n",
        "                bbox = BoundingBox.from_voc(*bbox)\n",
        "                bbox.image_size = (shape[1], shape[0])\n",
        "                yolo_bbox = bbox.to_yolo(return_values=True)\n",
        "                label += f\"{bboxes_temp.loc[i, 'worm_type']} {yolo_bbox[0]} {yolo_bbox[1]} {yolo_bbox[2]} {yolo_bbox[3]} \\n\"\n",
        "            except:\n",
        "                ids_to_remove.append(id)\n",
        "                try:\n",
        "                    os.remove(f'/content/train_images/{id}', )\n",
        "                except:\n",
        "                    pass\n",
        "                break\n",
        "        with open(f'/content/labels/{id.split(\".\")[0]}.txt', 'w') as f:\n",
        "            f.write(label)\n",
        "    except:\n",
        "        ids_to_remove.append(id)\n",
        "        try:\n",
        "            os.remove(f'/content/labels/{id}', )\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "\n",
        "list(map(make_labels, tqdm(train_bbox['image_id'].unique())))\n",
        "train_df = train[~train['image_id_worm'].isin(ids_to_remove)]\n",
        "train_df.to_csv('Train.csv', index=False)\n"
      ],
      "metadata": {
        "id": "YCHilf9a8tox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "\n",
        "bboxes = pd.read_csv('images_bboxes.csv')\n",
        "no_bbox = bboxes[bboxes['geometry'].isnull()]\n",
        "\n",
        "bboxes = bboxes.dropna(axis=0)\n",
        "images_len = {}\n",
        "for i in no_bbox['image_id'].unique():\n",
        "    i = i.split('.')[0]\n",
        "    images_len.update({f\"{i}_pbw.jpg\": 0, f\"{i}_abw.jpg\": 0})\n",
        "for i in tqdm(bboxes['image_id'].unique()):\n",
        "    bboxes_temp_pbw = bboxes[(bboxes['image_id'] == i) & (bboxes['worm_type'] == 'pbw')]\n",
        "    bboxes_temp_abw = bboxes[(bboxes['image_id'] == i) & (bboxes['worm_type'] == 'abw')]\n",
        "    i = i.split('.')[0]\n",
        "    images_len.update({f\"{i}_pbw.jpg\": len(bboxes_temp_pbw), f\"{i}_abw.jpg\": len(bboxes_temp_abw)})\n",
        "\n",
        "train_df = pd.DataFrame(images_len.items(), columns=['image_id', 'number_of_worms'])\n",
        "\n",
        "train_df.to_csv('train_modified.csv', index=False)\n"
      ],
      "metadata": {
        "id": "e7iTANsBBCYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install iterative-stratification\n"
      ],
      "metadata": {
        "id": "QmfGGQlKMX70"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "train_modified = pd.read_csv('train_modified.csv')\n",
        "train = pd.read_csv('Train.csv')\n",
        "ids = []\n",
        "pbw = []\n",
        "abw = []\n",
        "\n",
        "\n",
        "def append_labels(id):\n",
        "    ids.append(id)\n",
        "    id = id.split('.')[0]\n",
        "    pbw.append(train_modified[train_modified['image_id'] == f\"{id}_pbw.jpg\"]['number_of_worms'].values[0])\n",
        "    abw.append(train_modified[train_modified['image_id'] == f\"{id}_abw.jpg\"]['number_of_worms'].values[0])\n",
        "\n",
        "\n",
        "list(map(append_labels, train['image_id_worm'].values))\n",
        "train_kf = pd.DataFrame({'image_id': ids, 'pbw': pbw, 'abw': abw})\n",
        "\n",
        "\n",
        "def make_fold():\n",
        "    mskf = MultilabelStratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "    train_kf['fold'] = -1\n",
        "    num_bins = int(np.floor(1 + np.log2(len(train_kf))))\n",
        "    print(num_bins)\n",
        "    train_kf.loc[:, \"bins_1\"] = pd.cut(train_kf['pbw'], bins=num_bins, labels=False)\n",
        "    train_kf.loc[:, \"bins_2\"] = pd.cut(train_kf['abw'], bins=num_bins, labels=False)\n",
        "    print(train_kf.head())\n",
        "    for fold, (train_idx, val_idx) in enumerate(mskf.split(X=train_kf, y=train_kf[['bins_1', 'bins_2']].values)):\n",
        "        train_kf.loc[val_idx, 'fold'] = fold\n",
        "\n",
        "    train_kf.drop('bins_1', axis=1, inplace=True)\n",
        "    train_kf.drop('bins_2', axis=1, inplace=True)\n",
        "    labels_len_dict = {}\n",
        "    for i in range(5):\n",
        "        labels_len_dict.update({f'pbw_{i}': train_kf[train_kf['fold'] != i]['pbw'].sum()})\n",
        "        labels_len_dict.update({f'abw_{i}': train_kf[train_kf['fold'] != i]['abw'].sum()})\n",
        "    plt.bar(labels_len_dict.keys(), labels_len_dict.values())\n",
        "    plt.show()\n",
        "    return train_kf\n",
        "\n",
        "\n",
        "x = make_fold()\n",
        "x.to_csv('train_mskf_5_fold.csv', index=False)\n"
      ],
      "metadata": {
        "id": "CZDHPJLJCKa3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "import pandas as pd\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "train_kf = pd.read_csv('/content/train_mskf_5_fold.csv')\n",
        "os.makedirs('/content/data',exist_ok=True)\n",
        "for i in tqdm(range(5)):\n",
        "    val_df = train_kf[train_kf['fold'] == i].reset_index(drop=True)\n",
        "    os.makedirs('/content/data/dataset/fold_{}/images/'.format(i),\n",
        "                exist_ok=True)\n",
        "    os.makedirs('/content/data/dataset/fold_{}/labels/'.format(i), exist_ok=True)\n",
        "    for j in tqdm(val_df['image_id'].unique()):\n",
        "        shutil.copy(f'/content/train_images/{j}',\n",
        "                    f'/content/data/dataset/fold_{i}/images')\n",
        "        if os.path.exists(f'/content/labels/{j.split(\".\")[0]}.txt'):\n",
        "            shutil.copy(f'/content/labels/{j.split(\".\")[0]}.txt',\n",
        "                        f'/content/data/dataset/fold_{i}/labels')\n"
      ],
      "metadata": {
        "id": "2HMFu8OeMvN8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import yaml\n",
        "\n",
        "folds = list(range(5))\n",
        "for i in folds:\n",
        "    train_path = []\n",
        "    for j in range(5):\n",
        "        if i != j:\n",
        "            train_path.append(f'./dataset/fold_{j}/images/')\n",
        "\n",
        "    data = dict(\n",
        "        train=train_path,\n",
        "        val=f'./dataset/fold_{i}/images/',\n",
        "        names=['pbw', 'abw']\n",
        "    )\n",
        "    with open(f'/content/data/fold_{i}.yaml', 'w') as outfile:\n",
        "        yaml.dump(data, outfile, default_flow_style=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "AvocNcs4O9ac"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r data.zip data"
      ],
      "metadata": {
        "id": "28Dapj54PjoQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r test_images /content/test_images"
      ],
      "metadata": {
        "id": "AT2SVgWLeHHE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/test_images.zip /content/drive/MyDrive/data"
      ],
      "metadata": {
        "id": "eRlEr-VutgEZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xp_GBZdqvT6p"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "private_outputs": true,
      "mount_file_id": "1MJ93k8yWD2w6Xey-xgRv6NZi6pYTN6oK",
      "authorship_tag": "ABX9TyP0os26IkeSiMW+vc0er4dI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}